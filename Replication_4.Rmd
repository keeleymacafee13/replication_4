---
title: 'Replication 4: "What the Demolition of Public Housing Teaches Us about the
  Impact of Racial Threat on Political Behavior"'
author: "Keeley MacAfee"
date: "4/1/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Load libraries. 
library(apsrtable)
library(simpleboot)
library(boot)
library(MatchIt)
library(Zelig)
library(expint)
library(ei)
library(tidyverse)
```

# Abstract 
In "What the Demolition of Public Housing Teaches Us about the Impact of Racial Threat on Political Behavior," Ryan Enos examines the destruction of housing projects in Chicago and the effects it had on citizens' political behavior/preferences.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
## Load data
## Some other data is loaded throughout the code.
## Tried to load it in this chunk with the Tidyversian style, but it caused errors along the way.

# wtreat <- read_csv('dataverse_files/white.treat.effect.mean.boot.csv') 
# wtreat.lower <- read_csv('dataverse_files/white.treat.effect.conf.boot.lower.csv') 
# wtreat.upper <- read_csv('dataverse_files/white.treat.effect.conf.boot.upper.csv') 
# Nwtreat <- read_csv('dataverse_files/white.treat.N.csv')
# btreat <- read_csv('dataverse_files/black.treat.effect.mean.boot.csv') 
# btreat.lower <- read_csv('dataverse_files/black.treat.effect.conf.boot.lower.csv') 
# btreat.upper <- read_csv('dataverse_files/black.treat.effect.conf.boot.upper.csv') 
# Nbtreat <- read_csv('dataverse_files/black.treat.N.csv')
## Letters for marking graphs, one is not used
# use.letters = c('a','b','c','d','e','f','skip','g','h')
```


# Data Creation

```{r, echo=FALSE, message=FALSE, warning=FALSE}
data <- read.csv("data.turnout.csv")
```

```{r}
##set some data as factors for use below
data$reg = as.Date(data$reg)
data$p = as.factor(data$p)
data$s = as.factor(data$s)

##distances used repeatedly in estimation below
dists = seq(from = 100, to = 1000, by = 100)


##basic diff in diffs in paper, estimated across multiple definitions of white and distances

namepcts = c(seq(from = .91, to = .96, by = .01),.975,.99,1)

##matrices for stroing results
res.mat = matrix(nrow=length(namepcts),ncol=length(dists))

white.treat.N = res.mat
white.treat.effect.mean.boot = res.mat
white.treat.effect.conf.boot.lower = res.mat
white.treat.effect.conf.boot.upper = res.mat

black.treat.N = res.mat
black.treat.effect.mean.boot = res.mat
black.treat.effect.conf.boot.lower = res.mat
black.treat.effect.conf.boot.upper = res.mat

###registration is Illionis is cutoff 27 days prior to election day, limit to these individuals
use.data = data[data$reg<"2000-10-10"&is.na(data$reg)==F,]


##loop through definitions of white and distances and estimate at each combination
for(j in 1:length(namepcts)){
	##define a treatment and control group for each name percent
	useW = use.data[use.data$whitename>=namepcts[j],]
   useB = use.data[use.data$blackname>=namepcts[j],]
  
    for(h in 1:length(dists)){
      	Wtreat = useW[useW$demo.distance<=dists[h],]
      	Btreat = useB[useB$demo.distance<=dists[h],]
      	Wcont = useW[useW$demo.distance>dists[h],]
      	Bcont = useB[useB$demo.distance>dists[h],]     		
	
      	white.treat.N[j,h] = nrow(Wtreat)
      	black.treat.N[j,h] = nrow(Btreat)}}

```


```{r}
# parallel trends tests
# change in turnout overtime for black and white, treatment and control

# these are the elections to look at
elections = c('vote1996','vote1998','vote2000','vote2002','vote2004')

# matrices for storing results
outmat = matrix(nrow=length(elections), ncol=4)
colnames(outmat) = c('white.treatment','white.control','black.treatment','black.control')
# use different registration cutoff here because going all the way back to 1996
use.data = data[data$reg<"1996-10-08"&is.na(data$reg)==F,]

# define a treatment and control group for each name percent
useW = use.data[use.data$whitename>=.975,]
useB = use.data[use.data$blackname>=.975,]

# set distance for parallel trends test to 200 meters, can be tested at other distances too  
Wtreat = useW[useW$demo.distance<=200,]
Btreat = useB[useB$demo.distance<=200,]
Wcont = useW[useW$demo.distance>200,]
Bcont = useB[useB$demo.distance>200,]     		

WtreatN = nrow(Wtreat)
BtreatN = nrow(Btreat)
WcontN = nrow(Wcont)
BcontN = nrow(Bcont)

for(i in 1:length(elections)){
		election = elections[i]
		outmat[i,'white.treatment'] = sum(Wtreat[election],na.rm=T)/WtreatN
	   outmat[i,'black.treatment'] = sum(Btreat[election],na.rm=T)/BtreatN
	   outmat[i,'white.control'] = sum(Wcont[election],na.rm=T)/WcontN
	   outmat[i,'black.control'] = sum(Bcont[election],na.rm=T)/BcontN}

parallel.trends = outmat

```


```{r}
##now test for matched white subjects

###mats for storage
outmat = matrix(ncol=4,nrow = length(dists))
colnames(outmat) = c('coefficient','stdev','N.treatment','N.control')

##define data that will bs used for series of tests below
white.data = data[data$reg<"2000-10-10"&is.na(data$reg)==F,]

##only need subjects who qualify by name pcts
white.data = white.data[white.data$whitename>=.975,]

##only can use complete cases for matching, so extract those, first extract needed columns
use.data = white.data[,c('vote.change','demo.distance','p','s','age','age.squared','medianincome')]
use.data = use.data[complete.cases(use.data),]

##rename matrix for use in printing later
white.match.basic = outmat
```



```{r}
##now test for matched white subjects
##now using property controls
###mats for storage
outmat = matrix(ncol=4,nrow = length(dists))
colnames(outmat) = c('coefficient','stdev','N.treatment','N.control')

##only can use complete cases for matching, so extract those, first extract needed columns
use.data = white.data[,c('vote.change','demo.distance','p','s','age','age.squared','medianincome', 'prior.avg.value','deeded.strict')]
use.data = use.data[complete.cases(use.data),]

##rename matrix for use in printing later
white.match.basic.property = outmat
```


```{r}
##now test for matched white subjects against other whites near non-demolished projects
outmat = matrix(ncol=4,nrow = length(dists))
outmat.diffs = matrix(ncol=4,nrow = length(dists))
colnames(outmat) = c('coefficient','stdev','N.treatment','N.control')
colnames(outmat.diffs) = c('mean.diff','low.ci','high.ci','N')


use.data = white.data[,c('vote.change','demo.distance','nondemo.distance','p','s','age','age.squared','medianincome')]
use.data = use.data[complete.cases(use.data),]

##rename matrix for use in printing later
white.match.nondemolished = outmat
white.match.nondemolished.diffs = outmat.diffs
```



```{r}
##now test for matched white subjects against other whites near non-demolished projects
##controlling for property

outmat = matrix(ncol=4,nrow = length(dists))
outmat.diffs = matrix(ncol=4,nrow = length(dists))
colnames(outmat) = c('coefficient','stdev','N.treatment','N.control')
colnames(outmat.diffs) = c('mean.diff','low.ci','high.ci','N')

use.data = white.data[,c('vote.change','demo.distance','nondemo.distance','p','s','age','age.squared','medianincome','prior.avg.value','deeded.strict')]
use.data = use.data[complete.cases(use.data),]

##rename matrix for use in printing later
white.match.nondemolished.property = outmat
white.match.nondemolished.diffs.property = outmat.diffs
```


```{r}
##now test for matched white subjects against other whites near non-demolished projects
##controlling for local racial context

outmat = matrix(ncol=4,nrow = length(dists))
outmat.diffs = matrix(ncol=4,nrow = length(dists))
colnames(outmat) = c('coefficient','stdev','N.treatment','N.control')
colnames(outmat.diffs) = c('mean.diff','low.ci','high.ci','N')

use.data = white.data[,c('vote.change','demo.distance','nondemo.distance','p','s','age','age.squared','medianincome','pctblack')]
use.data = use.data[complete.cases(use.data),]

##rename matrix for use in printing later
white.match.nondemolished.localrace = outmat
white.match.nondemolished.diffs.localrace = outmat.diffs
```


```{r}
##match white subjects with black subjects


outmat = matrix(ncol=4,nrow = length(dists))
outmat.diffs = matrix(ncol=4,nrow = length(dists))
colnames(outmat) = c('coefficient','stdev','N.treatment','N.control')
colnames(outmat.diffs) = c('mean.diff','low.ci','high.ci','N')

white.black.data = data[data$reg<"2000-10-10"&is.na(data$reg)==F,]
white.black.data$white = ifelse(white.black.data$whitename>=.975,T,F)
white.black.data$black = ifelse(white.black.data$blackname>=.975,T,F)

##only need subjects who qualify by name pcts
white.black.data = white.black.data[white.black.data$white==T|white.black.data$black==T,]

##only can use complete cases for matching, so extract those, first extract needed columns
use.data = white.black.data[,c('vote.change','white','demo.distance','p','s','age','age.squared','medianincome','demo.gid'
)]
use.data = use.data[complete.cases(use.data),]

##rename matrix for use in printing later
white.match.black = outmat
white.match.black.diffs = outmat.diffs
```


```{r}
##match white subjects with black subjects
##use property
outmat = matrix(ncol=4,nrow = length(dists))
outmat.diffs = matrix(ncol=4,nrow = length(dists))
colnames(outmat) = c('coefficient','stdev','N.treatment','N.control')
colnames(outmat.diffs) = c('mean.diff','low.ci','high.ci','N')

##only can use complete cases for matching, so extract those, first extract needed columns
use.data = white.black.data[,c('vote.change','white','demo.distance','p','s','age','age.squared','medianincome',
'prior.avg.value','deeded.strict','demo.gid')]
print(nrow(use.data))
use.data = use.data[complete.cases(use.data),]


##rename matrix for use in printing later
white.match.black.property = outmat
white.match.black.diffs.property = outmat.diffs
```


```{r}
##create predicted effects for distance and context changes


##use data created above for whites
usedata = white.data


##create chunks for estimation
distances = seq(from = 10, to = 2000, by = 10)
areas = seq(from = 0, to = 1, length.out = length(distances))
			      
##storage bin
outmat.s = matrix(ncol = 5, nrow = 0)
outmat.d = matrix(ncol = 5, nrow = 0)

out.reg = zelig(vote2004~log(demo.distance)+log(context_black)+vote2000,data = usedata, model = 'ls', cite = F)

##begin simulations across variable values
#for(i in seq(1:length(distances))){
for(i in seq(1:length(distances))){
	use.distance = distances[i]
	out.d.1 = setx(out.reg,
		vote2000 = 1,
		demo.distance = use.distance)

	out.d.sims = sim(out.reg,
		x = out.d.1)
	
	use.area = areas[i]	
	out.s.1 = setx(out.reg,
		vote2000 = 1,
		demo.distance = 100,
		context_black = use.area)

	out.s.sims = sim(out.reg,
		x = out.s.1)

	outstats.d = summary(out.d.sims)$stats[[1]]
	outstats.s = summary(out.s.sims)$stats[[1]]
	
	outmat.d = rbind(outmat.d,outstats.d)
	outmat.s = rbind(outmat.s,outstats.s)
	}

##store results for graphics and table	
predicted.results.distance.vary.context = outmat.d
predicted.results.area.vary.context = outmat.s

out.reg.predictions = out.reg

```

# Vote Choice

```{r}
##load data, one data set for each Census/redistricting period
data.2000 = read.csv('dataverse_files/data.votechoice.2000.csv')
data.2010 = read.csv('dataverse_files/data.votechoice.2010.csv')

years = c('2000','2010')

```



```{r}
distance.subset = 1000 ##SETS THE DISTANCE UNDER WHICH TO ANALYZE THE RELATIONSHIP

##mats for storing results
outmat.distance = matrix(ncol = 10,nrow = 0)
outmat.demolished = matrix(ncol = 10,nrow = 0)

##variables needed for estimation for white and black subjects, will vary between them
whitevars = c('demo.distance','nondemo.distance','white_median_income','white.weight')
blackvars = c('demo.distance','nondemo.distance','black_median_income','black.weight')


###create formulas for below
white.treated.form = 'treated ~ white_median_income'
black.treated.form = 'treated ~ black_median_income'
	
##save results
rownames(outmat.distance) = NULL
outmat.distance = as.data.frame(outmat.distance)
colnames(outmat.distance) = c('election','group','t.value','df','p','diff','x.mean','y.mean','sd','treated.N')
outmat.distance$t.value = as.numeric(levels(outmat.distance[,'t.value']))[outmat.distance[,'t.value']]
outmat.distance$df = as.numeric(levels(outmat.distance[,'df']))[outmat.distance[,'df']]
outmat.distance$p = as.numeric(levels(outmat.distance[,'p']))[outmat.distance[,'p']]
outmat.distance$diff = as.numeric(levels(outmat.distance[,'diff']))[outmat.distance[,'diff']]
outmat.distance$x.mean = as.numeric(levels(outmat.distance[,'x.mean']))[outmat.distance[,'x.mean']]
outmat.distance$y.mean = as.numeric(levels(outmat.distance[,'y.mean']))[outmat.distance[,'y.mean']]
outmat.distance$sd = as.numeric(levels(outmat.distance[,'sd']))[outmat.distance[,'sd']]
outmat.distance$treated.N = as.numeric(levels(outmat.distance[,'treated.N']))[outmat.distance[,'treated.N']]

rownames(outmat.demolished) = NULL
outmat.demolished = as.data.frame(outmat.demolished)
colnames(outmat.demolished) = c('election','group','t.value','df','p','diff','x.mean','y.mean','sd','treated.N')
outmat.demolished$t.value = as.numeric(levels(outmat.demolished[,'t.value']))[outmat.demolished[,'t.value']]
outmat.demolished$df = as.numeric(levels(outmat.demolished[,'df']))[outmat.demolished[,'df']]
outmat.demolished$p = as.numeric(levels(outmat.demolished[,'p']))[outmat.demolished[,'p']]
outmat.demolished$diff = as.numeric(levels(outmat.demolished[,'diff']))[outmat.demolished[,'diff']]
outmat.demolished$x.mean = as.numeric(levels(outmat.demolished[,'x.mean']))[outmat.demolished[,'x.mean']]
outmat.demolished$y.mean = as.numeric(levels(outmat.demolished[,'y.mean']))[outmat.demolished[,'y.mean']]
outmat.demolished$sd = as.numeric(levels(outmat.demolished[,'sd']))[outmat.demolished[,'sd']]
outmat.demolished$treated.N = as.numeric(levels(outmat.demolished[,'treated.N']))[outmat.demolished[,'treated.N']]

##rename for plotting
distance.vote.differences = outmat.distance
demolished.vote.differences = outmat.demolished
	
```



# Figure 1

```{r fig1, echo=FALSE, message=FALSE, warning=FALSE}
# Figure 1

# Master graphic parameters (hard coding?) for graphics
ylims = c(-.35,.1)
ylims.2 = c(-.45,.1)
xlims = c(.5,11)
dists = seq(from = 1000, to = 100, by = -100)
xs = seq(1:length(dists))
ys = seq(from = -.35, to = .1, by = .05)
ys.lab = c('-0.35','-0.30', '-0.25','-0.20','-0.15','-0.10','-0.05','0.00','0.05','0.10')
ys.2 = seq(from = -.45, to = .1, by = .05)
ys.lab.2 = c('-0.45','-0.40','-0.35','-0.30', '-0.25','-0.20','-0.15','-0.10','-0.05','0.00','0.05','0.10')
offsets = .15
text.offsets = .025
cex.axis = .9
cex.N = .7
top.text.adj = c(1.3,1.3) ##offsets on labels to reduce crowding
bottom.text.adj = c(-.15,-.85)
point.size = 2
line.offset = .0175

# Cycle through each line of data, each of which are groups defined by diferent namepcts
	use.wtreat = as.matrix(wtreat[7,])
	use.wlower = as.matrix(wtreat.lower[7,])
	use.wupper = as.matrix(wtreat.upper[7,])
	use.Nwtreat = as.matrix(Nwtreat[7,])

	use.btreat = as.matrix(btreat[7,])
	use.blower = as.matrix(btreat.lower[7,])
	use.bupper = as.matrix(btreat.upper[7,])
	use.Nbtreat = as.matrix(Nbtreat[7,])
	

# Name graphs/details
	par(las = 1)
	par(mar = c(5.1, 4.1, .5, .5))
	plot(xs, use.wtreat,
		ylim = ylims,
		xlim = xlims,
		type = 'n',
		ylab = 'Treatment Effect',
		xlab = 'Treated Group Distance from Projects',
		xaxt = 'n',
		yaxt = 'n.csv')
	abline(h = 0, lty = 2)

# Draw lines first so they are covered by points
# Create spaces in lines using the offset (this allows the N to be displayed with the text() function)
# Black lines are offset to the left, white lines to the right	
	
	segments(x0= xs[1:2]+offsets, x1 = xs[1:2]+offsets, 
	         
# Only do it for low N blacks because otherwise lines look funny

		y0 = use.btreat[,1:2], y1 =	use.blower[,1:2])
	segments(x0= xs[1:2]+offsets, x1 = xs[1:2]+offsets,
		y0 = use.btreat[,1:2] + line.offset, 	y1 =	use.bupper[,1:2])
	
# Now the others
	
	segments(x0= xs[3:10]+offsets, x1 = xs[3:10]+offsets,
		y0 = use.blower[,3:10], 	y1 =	use.bupper[,3:10])
	
# Bottom lines
	segments(x0= xs-offsets, x1 = xs-offsets, 
		y0 = use.wtreat - line.offset, 	y1 =	use.wlower)
	
# Top lines
	segments(x0= xs-offsets, x1 = xs-offsets, 
		y0 = use.wtreat, 	y1 =	use.wupper)

  
# Points and N descriptions
	points(xs-offsets, use.wtreat,
	       cex = point.size,
	       pch = 21, 
	       bg = 'white',
	       col = 'black')
	text(xs-offsets,use.wtreat,
	     paste('(',use.Nwtreat,')',sep = ''),
	     cex = cex.N,
	     #adj = top.text.adj
	     pos = 1)
	
	points(xs+offsets, use.btreat,
	       pch = 16,
	       cex = point.size)
	text(xs+offsets,use.btreat,
	     paste('(',use.Nbtreat,')',sep = ''),
	     cex = cex.N,
	     #adj = bottom.text.adj
	     pos = 3)
# Formatting
	axis(side = 1,
		at = xs,
		label = seq(100,1000,100),
		cex.axis = cex.axis)
	axis(side = 2,
		at = ys,
		label = ys.lab,
		cex.axis = cex.axis)	

```


# Figures 2

```{r fig 2 and 3, echo=FALSE, message=FALSE, warning=FALSE}
# Figure 2 

# Removed parts of this code by trial and error because I originally got several different 
# graphs in addition to the ones created in the paper.
# Not really sure how to separate the figures into different code chunks.
# EDIT: getting rid of for loop makes plots separable
treat <- read_csv('dataverse_files/white.match.nondemolished.csv')
diffs <- read_csv('dataverse_files/white.match.nondemolished.diffs.csv')

			use.ylims = ylims
			use.ys.lab = ys.lab
			use.ys = ys
	
			use.treat = treat$coefficient			
			clower = use.treat-(1.96*treat$stdev)
			cupper = use.treat+(1.96*treat$stdev)
			use.N.treat = treat$N.treatment + treat$N.control
						
			par(las = 1)
			par(mar = c(5.1, 4.1, .5, .5))
			plot(xs, use.treat,
				ylim = use.ylims,
				xlim = xlims,
				type = 'n',
				ylab = 'Treatment Effect',
				xlab = 'Treated Group Distance from Projects',
				xaxt = 'n',
				yaxt = 'n')
			abline(h = 0, lty = 2)
				
			segments(x0=xs,x1=xs,
						y0= use.treat+line.offset,y1=cupper)
			segments(x0=xs,x1=xs,
						y0= use.treat,y1=clower)
	
# Treatment Effects.
# Not totally sure what all of this does. 
			
			points(xs, use.treat, 
				pch = 17, 
				cex = point.size,
					bg = 'white',
       			col = 'black')
			text(xs,use.treat,
			     paste('(',use.N.treat,')',sep = ''),
			     cex = cex.N,
			     pos = 3)
			axis(side = 1,
					at = xs,
					label = seq(100,1000,100),
					cex.axis = cex.axis)
			axis(side = 2,
					at = use.ys,
					label = use.ys.lab,
					cex.axis = cex.axis)
	
```



# Figure 3

```{r fig3, echo=FALSE, message=FALSE, warning=FALSE}
treat3 <- read_csv('dataverse_files/white.match.black.property.csv')
diffs3 <- read_csv('dataverse_files/white.match.black.diffs.property.csv')

use.ylims = ylims
			use.ys.lab = ys.lab
			use.ys = ys
	
			use.treat = treat3$coefficient			
			clower = use.treat-(1.96*treat3$stdev)
			cupper = use.treat+(1.96*treat3$stdev)
			use.N.treat = treat3$N.treatment + treat3$N.control
						
			par(las = 1)
			par(mar = c(5.1, 4.1, .5, .5))
			plot(xs, use.treat,
				ylim = use.ylims,
				xlim = xlims,
				type = 'n',
				ylab = 'Treatment Effect',
				xlab = 'Treated Group Distance from Projects',
				xaxt = 'n',
				yaxt = 'n')
			abline(h = 0, lty = 2)
				
			segments(x0=xs,x1=xs,
						y0= use.treat+line.offset,y1=cupper)
			segments(x0=xs,x1=xs,
						y0= use.treat,y1=clower)
	
# Treatment Effects.
# Not totally sure what all of this does. 
			
			points(xs, use.treat, 
				pch = 17, 
				cex = point.size,
					bg = 'white',
       			col = 'black')
			text(xs,use.treat,
			     paste('(',use.N.treat,')',sep = ''),
			     cex = cex.N,
			     pos = 3)
			axis(side = 1,
					at = xs,
					label = seq(100,1000,100),
					cex.axis = cex.axis)
			axis(side = 2,
					at = use.ys,
					label = use.ys.lab,
					cex.axis = cex.axis)

```


# Figure 4

```{r fig4a, echo=FALSE, message=FALSE, warning=FALSE}
# Figure 4a

distdat = read.csv('dataverse_files/predicted.results.distance.vary.context.csv')
colnames(distdat) <- c("mean","sd","50%","2.5%","97.5%")


# New ylims for these graphs
ylims.predict = c(.6,.75)

# Parameters to be used in graphs.
xsa = seq(from = 10, to = 2000, by = 10)


		par(las = 1)
		par(mar = c(5.1, 4.1, .5, .5), mai = c(1.22,0.82,0.82,0.1))
		plot(xsa, distdat[,'mean'],
			type = 'l',
			xlab = 'Distance from Project',
			ylab = expression(Pr(vote[2004])),
			ylim = ylims.predict,
			xaxt = 'n',
			cex.axis = cex.axis,
			lwd = 4)
		
# Put horizontal and vertical lines on plots.
	abline(h = seq(from = min(ylims.predict), to = max(ylims.predict), by = .025),
	       lty = 2,
	       col = 'gray',
	       lwd = 1)
	abline(v = seq(from = 0, to = 2000, by = 200), 
	       lty = 2,
	       col = 'gray',
	       lwd = 1)
	lines(xsa, distdat[,'2.5%'],
			lty = 3,
			lwd = 2.5)
	lines(xsa, distdat[,'97.5%'],
			lty = 3,
			lwd = 2.5)

axis(side = 1, 
		at = seq(from = 0, to = 2000, by = 200),
     labels = as.character(seq(from = 0, to = 2000, by = 200)),
		cex.axis = cex.axis)
```


```{r fig4b, echo=FALSE, message=FALSE, warning=FALSE}
# Figure 4b
areadat = read.csv('dataverse_files/predicted.results.area.vary.context.csv')
colnames(areadat) <- c("mean","sd","50%","2.5%","97.5%")

# Parameters.
xsb = seq(from = 45000, to = 1004000, by = 4800)/1000

	par(las = 1)
		par(mar = c(5.1, 4.1, .5, .5), mai = c(1.22,0.82,0.82,0.1))
		plot(xsb, areadat[,'mean'],
			type = 'l',
			xlab = 'Percent of Local Black Population in Demolished Project',
			ylab = expression(Pr(vote[2004])),
			ylim = ylims.predict,
			xaxt = 'n',
			cex.axis = cex.axis,
			lwd = 4)
		
# Put horizontal and vertical lines on plots
	abline(h = seq(from = min(ylims.predict), to = max(ylims.predict), by = .025),
	       lty = 2,
	       col = 'gray',
	       lwd = 1)
	abline(v = seq(from = 0, to = 2000, by = 200), 
	       lty = 2,
	       col = 'gray',
	       lwd = 1)
	lines(xsb, areadat[,'2.5%'],
			lty = 3,
			lwd = 2.5)
	lines(xsb, areadat[,'97.5%'],
			lty = 3,
			lwd = 2.5)
	

  axis(side = 1, 
		at = seq(from = 0, to = 1000, by = 100),
		# Hard coding axis labels. Help from Enxhis code from class.
     labels = as.character(c('0','10%','20%','30%','40%','50%','60%','70%','80%','90%','100%')),
		cex.axis = cex.axis)

```


# Figures 5 and 6


```{r fig5, echo=FALSE, message=FALSE, warning=FALSE}
# Figures 5 and 6
# Again, I couldn't figure out how to break up the figures into different chunks.

pres.elections = c('dole_pct_ei','bush2000_pct_ei','bush2004_pct_ei','mccain_pct_ei')
obama.elections = c('obama_sen_primary_pct_ei','keyes_pct_ei','obama_pres_primary_pct_ei')

dists = read.csv('dataverse_files/distance.vote.differences.csv')
demos = read.csv('dataverse_files/demolished.vote.differences.csv')


graphs = c('5a','5b','6')

for(i in graphs){

	if(i == '5a'){dat = dists}
	else{dat = demos}
		
	if(i %in% c('5a','5b')){
		xlims = c(.75,4.25)
		ylims = c(-.1,.2)	
		}
	else{
		xlims = c(.75,3.25)
		ylims = c(-.1,.25)
		}

# Recode Keyes to Obama general for presentation purposes
	dat[dat$election == 'keyes_pct_ei','x.mean'] = 1 - dat[dat$election == 'keyes_pct_ei','x.mean']
	
	dat[dat$election == 'keyes_pct_ei','y.mean'] = 1 - dat[dat$election == 'keyes_pct_ei','y.mean']
	
	dat[dat$election == 'keyes_pct_ei','diff'] =dat[dat$election == 'keyes_pct_ei','y.mean'] - dat[dat$election == 'keyes_pct_ei','x.mean']
	
		par(las = 1)
		par(mar = c(5.1, 4.1, .5, 1.5))
		plot(seq(1:4),
			rep(1,4),
			ylim = ylims,
			xlim = xlims, 
			type = 'n',
			xaxt = 'n',
			yaxt = 'n',
			xlab = 'Election',
			ylab = ifelse(i == '5b','','Treatment Effect')
			)
		abline(h=0, lty = 2)
		
		if(i %in% c('5a','5b')){
			segments(
				x0= seq(1:4)-offsets, 
				x1 = seq(1:4)-offsets,
				y0 = dat[dat$group == 'white'&dat$election %in% pres.elections,'diff']-(1.96*dat[dat$group == 'white'&dat$election %in% pres.elections,'sd']),
				y1 =	dat[dat$group == 'white'&dat$election %in% pres.elections,'diff']+(1.96*dat[dat$group == 'white'&dat$election %in% pres.elections,'sd'])	
					)
			points(seq(1:4)-offsets,
				dat[dat$group == 'white'&dat$election %in% pres.elections,'diff'],
					pch = 21, 
					bg = 'white',
					col = 'black',
					cex = 2
				)
			segments(
				x0= seq(1:4)+offsets, 
				x1 = seq(1:4)+offsets,
				y0 = dat[dat$group == 'black'&dat$election %in% pres.elections,'diff']-(1.96*dat[dat$group == 'black'&dat$election %in% pres.elections,'sd']),
				y1 =	dat[dat$group == 'black'&dat$election %in% pres.elections,'diff']+(1.96*dat[dat$group == 'black'&dat$election %in% pres.elections,'sd'])	
					)
			points(seq(1:4)+offsets,
				dat[dat$group == 'black'&dat$election %in% pres.elections,'diff'],
					pch = 16,
					cex = 2
				)
			axis(side = 1, at = seq(1:4), 
				c('1996','2000','2004','2008'), 
				tick = F,
				cex.axis = cex.axis)		
		}
		
		else{
			segments(
				x0= seq(1:3)-offsets, 
				x1 = seq(1:3)-offsets,
				y0 = dat[dat$group == 'white'&dat$election %in% obama.elections,'diff']-(1.96*dat[dat$group == 'white'&dat$election %in% obama.elections,'sd']),
				y1 =	dat[dat$group == 'white'&dat$election %in% obama.elections,'diff']+(1.96*dat[dat$group == 'white'&dat$election %in% obama.elections,'sd'])
					)
		  
			points(seq(1:3)-offsets,
				dat[dat$group == 'white'&dat$election %in% obama.elections,'diff'],
					pch = 21, 
					bg = 'white',
					col = 'black',
					cex = 2
				)
			
			segments(
				x0= seq(1:3)+offsets, 
				x1 = seq(1:3)+offsets,
				y0 = dat[dat$group == 'black'&dat$election %in% obama.elections,'diff']-(1.96*dat[dat$group == 'black'&dat$election %in% obama.elections,'sd']),
				y1 =	dat[dat$group == 'black'&dat$election %in% obama.elections,'diff']+(1.96*dat[dat$group == 'black'&dat$election %in% obama.elections,'sd'])	        )
			
  			points(seq(1:3)+offsets,
				dat[dat$group == 'black'&dat$election %in% obama.elections,'diff'],
					pch = 16,
					cex = 2
				)
  			
		axis(side = 1, at = seq(1:3), 
					c('2004 \n Senate Primary','2004 \n Senate General','2008 \n President Primary'),
					tick = F,
					cex.axis = cex.axis
					)
		
		}
		
		axis(side = 2,
			at = seq(from = -.1, to = .3, by = .05),
			label = c('-0.10','-0.05','0.00','0.05','0.10','0.15','0.20','0.25','0.30'),
			cex.axis = cex.axis
			)			
	
	}		
				
```




# References

Enos, Ryan D. 2016. “What the Demolition of Public Housing Teaches Us about the Impact of Racial Threat on Political Behavior.” American Journal of Political Science 60 (1): 123-142

