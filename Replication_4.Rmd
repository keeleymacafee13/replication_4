---
title: 'Replication 4: "What the Demolition of Public Housing Teaches Us about the
  Impact of Racial Threat on Political Behavior"'
author: "Keeley MacAfee"
date: "4/1/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Load libraries. 
library(apsrtable)
library(simpleboot)
library(boot)
library(MatchIt)
library(Zelig)
library(expint)
library(ei)
library(tidyverse)

# Note: would not let me knit as a PDF because there were 50 or more warnings.
```

# Abstract 
In "What the Demolition of Public Housing Teaches Us about the Impact of Racial Threat on Political Behavior," Ryan Enos examines the destruction of housing projects in Chicago and the effects it had on citizens' political behavior/preferences. Enos finds that white people living close to a project tended to vote less once the project was demolished. 


```{r, echo=FALSE, message=FALSE, warning=FALSE}
## Load data
## Some other data is loaded throughout the code.
## Tried to load it in this chunk with the Tidyversian style, but it caused errors along the way.
# For week 2, important that data is created; have csvs commented out from week 1.

# wtreat <- read_csv('dataverse_files/white.treat.effect.mean.boot.csv')
# wtreat.lower <- read_csv('dataverse_files/white.treat.effect.conf.boot.lower.csv')
# wtreat.upper <- read_csv('dataverse_files/white.treat.effect.conf.boot.upper.csv')
# Nwtreat <- read_csv('dataverse_files/white.treat.N.csv')
# btreat <- read_csv('dataverse_files/black.treat.effect.mean.boot.csv')
# btreat.lower <- read_csv('dataverse_files/black.treat.effect.conf.boot.lower.csv')
# btreat.upper <- read_csv('dataverse_files/black.treat.effect.conf.boot.upper.csv')
# Nbtreat <- read_csv('dataverse_files/black.treat.N.csv')
# # Letters for marking graphs, one is not used
# use.letters = c('a','b','c','d','e','f','skip','g','h')
```


# Data Creation

```{r readin, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
# This is the large csv which creates all of the subset, smaller csvs.
# Too large to push, so must be downloaded by hand. 
data <- read.csv("data.turnout.csv")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Set some data as factors for use below
data$reg = as.Date(data$reg)
data$p = as.factor(data$p)
data$s = as.factor(data$s)

# Distances used repeatedly in estimation below
dists = seq(from = 100, to = 1000, by = 100)


# Basic diff in diffs in paper, estimated across multiple definitions of white and distances
namepcts = c(seq(from = .91, to = .96, by = .01),.975,.99,1)

# Matrices for stroing results
res.mat = matrix(nrow=length(namepcts),ncol=length(dists))

# Creating empty matrices which will later become data frames.
white.treat.N = res.mat
white.treat.effect.mean.boot = res.mat
white.treat.effect.conf.boot.lower = res.mat
white.treat.effect.conf.boot.upper = res.mat

black.treat.N = res.mat
black.treat.effect.mean.boot = res.mat
black.treat.effect.conf.boot.lower = res.mat
black.treat.effect.conf.boot.upper = res.mat

# Registration is Illionis is cutoff 27 days prior to election day, limit to these individuals
use.data = data[data$reg<"2000-10-10"&is.na(data$reg)==F,]

```


```{r loop, echo=FALSE, cache=TRUE, message=FALSE, warning=FALSE}
# Loop through definitions of white and distances and estimate at each combination.
# Setting j = 7 makes the loop go through 7 rows? at 95% CI?. Per Gabes recommendation,
# I also set R = 2. In any case, this loop almost made my computer explode and took over an hour
# to run, though it got slightly better with the modifications. I don't know if that is because my computer is small?
# All of the dataframe names and structures were created above, but with
# all NAs as values. This loop, it seems, is key for storing values/CIs in the dataframes. 
j <- 7
for(j in 1:length(namepcts)){
	##define a treatment and control group for each name percent
	useW = use.data[use.data$whitename>=namepcts[j],]
   useB = use.data[use.data$blackname>=namepcts[j],]
  
    for(h in 1:length(dists)){
      	Wtreat = useW[useW$demo.distance<=dists[h],]
      	Btreat = useB[useB$demo.distance<=dists[h],]
      	Wcont = useW[useW$demo.distance>dists[h],]
      	Bcont = useB[useB$demo.distance>dists[h],]     		
	
      	white.treat.N[j,h] = nrow(Wtreat)
      	black.treat.N[j,h] = nrow(Btreat)
	      	
	   # For white and black subjects, perform t test of differences of means with boostrapped standard errors  	
		if(white.treat.N[j,h] > 0){
			white.boot = two.boot((Wtreat$vote2004-Wtreat$vote2000),(Wcont$vote2004-Wcont$vote2000),mean, R = 2, na.rm=T)
			white.treat.effect.mean.boot[j,h] = white.boot$t0
			white.boot.ci = boot.ci(white.boot, type = 'basic')
			white.treat.effect.conf.boot.lower[j,h] = white.boot.ci$basic[4]
			white.treat.effect.conf.boot.upper[j,h] = white.boot.ci$basic[5]
		      		}
		      		
		if(black.treat.N[j,h] > 0){
			black.boot = two.boot((Btreat$vote2004-Btreat$vote2000),(Bcont$vote2004-Bcont$vote2000),mean, R = 2, na.rm=T)
			black.treat.effect.mean.boot[j,h] = black.boot$t0
			black.boot.ci = boot.ci(black.boot, type = 'basic')
			black.treat.effect.conf.boot.lower[j,h] = black.boot.ci$basic[4]
			black.treat.effect.conf.boot.upper[j,h] = black.boot.ci$basic[5]		
			 }
			 }
	}

```


```{r matrices, echo=FALSE, message=FALSE, warning=FALSE}
# Change in turnout overtime for black and white, treatment and control
# These are the elections to look at
elections = c('vote1996','vote1998','vote2000','vote2002','vote2004')

# Matrices for storing results
outmat = matrix(nrow=length(elections), ncol=4)
colnames(outmat) = c('white.treatment','white.control','black.treatment','black.control')

# Use different registration cutoff here because going all the way back to 1996
use.data = data[data$reg<"1996-10-08"&is.na(data$reg)==F,]

# Define a treatment and control group for each name percent
useW = use.data[use.data$whitename>=.975,]
useB = use.data[use.data$blackname>=.975,]

# Set distance for parallel trends test to 200 meters, can be tested at other distances too  
Wtreat = useW[useW$demo.distance<=200,]
Btreat = useB[useB$demo.distance<=200,]
Wcont = useW[useW$demo.distance>200,]
Bcont = useB[useB$demo.distance>200,]     		

WtreatN = nrow(Wtreat)
BtreatN = nrow(Btreat)
WcontN = nrow(Wcont)
BcontN = nrow(Bcont)

# Looping through the values created above for residents at distances up to 200 meters and beyond 200 meters. 
for(i in 1:length(elections)){
		election = elections[i]
		outmat[i,'white.treatment'] = sum(Wtreat[election],na.rm=T)/WtreatN
	   outmat[i,'black.treatment'] = sum(Btreat[election],na.rm=T)/BtreatN
	   outmat[i,'white.control'] = sum(Wcont[election],na.rm=T)/WcontN
	   outmat[i,'black.control'] = sum(Bcont[election],na.rm=T)/BcontN}

parallel.trends = outmat

```


```{r whitematch, echo=FALSE, message=FALSE, warning=FALSE}
# Now test for matched white subjects

# Mats for storage
outmat = matrix(ncol=4,nrow = length(dists))
colnames(outmat) = c('coefficient','stdev','N.treatment','N.control')

# Define data that will bs used for series of tests below
white.data = data[data$reg<"2000-10-10"&is.na(data$reg)==F,]

# Only need subjects who qualify by name pcts
white.data = white.data[white.data$whitename>=.975,]

# Only can use complete cases for matching, so extract those, first extract needed columns
use.data = white.data[,c('vote.change','demo.distance','p','s','age','age.squared','medianincome')]
use.data = use.data[complete.cases(use.data),]

# Rename matrix for use in printing later; outmat makes the data suitable for printing
white.match.basic = outmat

# Now test for matched white subjects using property controls
# Mats for storage
outmat = matrix(ncol=4,nrow = length(dists))
colnames(outmat) = c('coefficient','stdev','N.treatment','N.control')

# Only can use complete cases for matching, so extract those, first extract needed columns
use.data = white.data[,c('vote.change','demo.distance','p','s','age','age.squared','medianincome', 'prior.avg.value','deeded.strict')]
use.data = use.data[complete.cases(use.data),]

# Rename matrix for use in printing later
white.match.basic.property = outmat

# Now test for matched white subjects against other whites near non-demolished projects
outmat = matrix(ncol=4,nrow = length(dists))
outmat.diffs = matrix(ncol=4,nrow = length(dists))
colnames(outmat) = c('coefficient','stdev','N.treatment','N.control')
colnames(outmat.diffs) = c('mean.diff','low.ci','high.ci','N')


use.data = white.data[,c('vote.change','demo.distance','nondemo.distance','p','s','age','age.squared','medianincome')]
use.data = use.data[complete.cases(use.data),]

# Rename matrix for use in printing later
white.match.nondemolished = outmat
white.match.nondemolished.diffs = outmat.diffs

# Now test for matched white subjects against other whites near non-demolished projects
# Controlling for property

outmat = matrix(ncol=4,nrow = length(dists))
outmat.diffs = matrix(ncol=4,nrow = length(dists))
colnames(outmat) = c('coefficient','stdev','N.treatment','N.control')
colnames(outmat.diffs) = c('mean.diff','low.ci','high.ci','N')

use.data = white.data[,c('vote.change','demo.distance','nondemo.distance','p','s','age','age.squared','medianincome','prior.avg.value','deeded.strict')]
use.data = use.data[complete.cases(use.data),]

# Rename matrix for use in printing later
white.match.nondemolished.property = outmat
white.match.nondemolished.diffs.property = outmat.diffs

# Now test for matched white subjects against other whites near non-demolished projects
# Controlling for local racial context

outmat = matrix(ncol=4,nrow = length(dists))
outmat.diffs = matrix(ncol=4,nrow = length(dists))
colnames(outmat) = c('coefficient','stdev','N.treatment','N.control')
colnames(outmat.diffs) = c('mean.diff','low.ci','high.ci','N')

use.data = white.data[,c('vote.change','demo.distance','nondemo.distance','p','s','age','age.squared','medianincome','pctblack')]
use.data = use.data[complete.cases(use.data),]

# Rename matrix for use in printing later
white.match.nondemolished.localrace = outmat
white.match.nondemolished.diffs.localrace = outmat.diffs
```


```{r whitematchblack, echo=FALSE, message=FALSE, warning=FALSE}
# Match white subjects with black subjects
outmat = matrix(ncol=4,nrow = length(dists))
outmat.diffs = matrix(ncol=4,nrow = length(dists))
colnames(outmat) = c('coefficient','stdev','N.treatment','N.control')
colnames(outmat.diffs) = c('mean.diff','low.ci','high.ci','N')

white.black.data = data[data$reg<"2000-10-10"&is.na(data$reg)==F,]
white.black.data$white = ifelse(white.black.data$whitename>=.975,T,F)
white.black.data$black = ifelse(white.black.data$blackname>=.975,T,F)

# Only need subjects who qualify by name pcts
white.black.data = white.black.data[white.black.data$white==T|white.black.data$black==T,]

# Only can use complete cases for matching, so extract those, first extract needed columns
use.data = white.black.data[,c('vote.change','white','demo.distance','p','s','age','age.squared','medianincome','demo.gid'
)]
use.data = use.data[complete.cases(use.data),]

# Rename matrix for use in printing later
white.match.black = outmat
white.match.black.diffs = outmat.diffs

# Match white subjects with black subjects
# Use property
outmat = matrix(ncol=4,nrow = length(dists))
outmat.diffs = matrix(ncol=4,nrow = length(dists))
colnames(outmat) = c('coefficient','stdev','N.treatment','N.control')
colnames(outmat.diffs) = c('mean.diff','low.ci','high.ci','N')

# Only can use complete cases for matching, so extract those, first extract needed columns
use.data = white.black.data[,c('vote.change','white','demo.distance','p','s','age','age.squared','medianincome',
'prior.avg.value','deeded.strict','demo.gid')]
print(nrow(use.data))
use.data = use.data[complete.cases(use.data),]


# Rename matrix for use in printing later
white.match.black.property = outmat
white.match.black.diffs.property = outmat.diffs
```


```{r votechoice, echo=FALSE, message=FALSE, warning=FALSE}
# Load data, one data set for each Census/redistricting period. These are the original, larger csvs with voting data. 
data.2000 = read.csv('dataverse_files/data.votechoice.2000.csv')
data.2010 = read.csv('dataverse_files/data.votechoice.2010.csv')

years = c('2000','2010')
```


```{r savedata, echo=FALSE, message=FALSE, warning=FALSE}
	
distance.subset = 1000 # SETS THE DISTANCE UNDER WHICH TO ANALYZE THE RELATIONSHIP

# Mats for storing results
outmat.distance = matrix(ncol = 10,nrow = 0)
outmat.demolished = matrix(ncol = 10,nrow = 0)

# Variables needed for estimation for white and black subjects, will vary between them
whitevars = c('demo.distance','nondemo.distance','white_median_income','white.weight')
blackvars = c('demo.distance','nondemo.distance','black_median_income','black.weight')


# Create formulas for below
white.treated.form = 'treated ~ white_median_income'
black.treated.form = 'treated ~ black_median_income'


# Saving results
rownames(outmat.distance) = NULL
outmat.distance = as.data.frame(outmat.distance)
colnames(outmat.distance) = c('election','group','t.value','df','p','diff','x.mean','y.mean','sd','treated.N')
outmat.distance$t.value = as.numeric(levels(outmat.distance[,'t.value']))[outmat.distance[,'t.value']]
outmat.distance$df = as.numeric(levels(outmat.distance[,'df']))[outmat.distance[,'df']]
outmat.distance$p = as.numeric(levels(outmat.distance[,'p']))[outmat.distance[,'p']]
outmat.distance$diff = as.numeric(levels(outmat.distance[,'diff']))[outmat.distance[,'diff']]
outmat.distance$x.mean = as.numeric(levels(outmat.distance[,'x.mean']))[outmat.distance[,'x.mean']]
outmat.distance$y.mean = as.numeric(levels(outmat.distance[,'y.mean']))[outmat.distance[,'y.mean']]
outmat.distance$sd = as.numeric(levels(outmat.distance[,'sd']))[outmat.distance[,'sd']]
outmat.distance$treated.N = as.numeric(levels(outmat.distance[,'treated.N']))[outmat.distance[,'treated.N']]

rownames(outmat.demolished) = NULL
outmat.demolished = as.data.frame(outmat.demolished)
colnames(outmat.demolished) = c('election','group','t.value','df','p','diff','x.mean','y.mean','sd','treated.N')
outmat.demolished$t.value = as.numeric(levels(outmat.demolished[,'t.value']))[outmat.demolished[,'t.value']]
outmat.demolished$df = as.numeric(levels(outmat.demolished[,'df']))[outmat.demolished[,'df']]
outmat.demolished$p = as.numeric(levels(outmat.demolished[,'p']))[outmat.demolished[,'p']]
outmat.demolished$diff = as.numeric(levels(outmat.demolished[,'diff']))[outmat.demolished[,'diff']]
outmat.demolished$x.mean = as.numeric(levels(outmat.demolished[,'x.mean']))[outmat.demolished[,'x.mean']]
outmat.demolished$y.mean = as.numeric(levels(outmat.demolished[,'y.mean']))[outmat.demolished[,'y.mean']]
outmat.demolished$sd = as.numeric(levels(outmat.demolished[,'sd']))[outmat.demolished[,'sd']]
outmat.demolished$treated.N = as.numeric(levels(outmat.demolished[,'treated.N']))[outmat.demolished[,'treated.N']]

# Rename for plotting
distance.vote.differences = outmat.distance
demolished.vote.differences = outmat.demolished
	
```

```{r finaldata, echo=FALSE, message=FALSE, warning=TRUE}
# The ultimate goal of this data creation is to not need to read in the csvs at the beginning in order 
# for the code to run. All of the matrices that were created and then filled in get stored in the environment
wtreat = as.data.frame(white.treat.effect.mean.boot)
wtreat.lower = as.data.frame(white.treat.effect.conf.boot.lower)
wtreat.upper = as.data.frame(white.treat.effect.conf.boot.upper)
Nwtreat = as.data.frame(white.treat.N)
btreat = as.data.frame(black.treat.effect.mean.boot)
btreat.lower = as.data.frame(black.treat.effect.conf.boot.lower)
btreat.upper = as.data.frame(black.treat.effect.conf.boot.upper)
Nbtreat = as.data.frame(black.treat.N)
# Letters for marking graphs, one is not used
use.letters = c('a','b','c','d','e','f','skip','g','h')
```


# Figure 1 Treatment Effects

```{r fig1, echo=FALSE, message=FALSE, warning=FALSE}
# Figure 1


# Master graphic parameters (hard coding?) for graphics
ylims = c(-.35,.1)
ylims.2 = c(-.45,.1)
xlims = c(.5,11)
dists = seq(from = 1000, to = 100, by = -100)
xs = seq(1:length(dists))
ys = seq(from = -.35, to = .1, by = .05)
ys.lab = c('-0.35','-0.30', '-0.25','-0.20','-0.15','-0.10','-0.05','0.00','0.05','0.10')
ys.2 = seq(from = -.45, to = .1, by = .05)
ys.lab.2 = c('-0.45','-0.40','-0.35','-0.30', '-0.25','-0.20','-0.15','-0.10','-0.05','0.00','0.05','0.10')
offsets = .15
text.offsets = .025
cex.axis = .9
cex.N = .7
top.text.adj = c(1.3,1.3) ##offsets on labels to reduce crowding
bottom.text.adj = c(-.15,-.85)
point.size = 2
line.offset = .0175

# Cycle through each line of data, each of which are groups defined by diferent namepcts
	use.wtreat = as.matrix(wtreat[7,])
	use.wlower = as.matrix(wtreat.lower[7,])
	use.wupper = as.matrix(wtreat.upper[7,])
	use.Nwtreat = as.matrix(Nwtreat[7,])

	use.btreat = as.matrix(btreat[7,])
	use.blower = as.matrix(btreat.lower[7,])
	use.bupper = as.matrix(btreat.upper[7,])
	use.Nbtreat = as.matrix(Nbtreat[7,])
	

# Name graphs/details
	par(las = 1)
	par(mar = c(5.1, 4.1, .5, .5))
	plot(xs, use.wtreat,
		ylim = ylims,
		xlim = xlims,
		type = 'n',
		ylab = 'Treatment Effect',
		xlab = 'Treated Group Distance from Projects',
		xaxt = 'n',
		yaxt = 'n.csv')
	abline(h = 0, lty = 2)

# Draw lines first so they are covered by points
# Create spaces in lines using the offset (this allows the N to be displayed with the text() function)
# Black lines are offset to the left, white lines to the right	
	
	segments (x0 = xs[1:2] + offsets, x1 = xs[1:2] + offsets, 
	         
# Only do it for low N blacks because otherwise lines look funny

		y0 = use.btreat[,1:2], y1 =	use.blower[,1:2])
	
	segments(x0= xs[1:2]+offsets, x1 = xs[1:2]+offsets,
		y0 = use.btreat[,1:2] + line.offset, 	y1 =	use.bupper[,1:2])
	
# Now the others
	
	segments(x0= xs[3:10]+offsets, x1 = xs[3:10]+offsets,
		y0 = use.blower[,3:10], 	y1 =	use.bupper[,3:10])
	
# Bottom lines
	segments(x0= xs-offsets, x1 = xs-offsets, 
		y0 = use.wtreat - line.offset, 	y1 =	use.wlower)
	
# Top lines
	segments(x0= xs-offsets, x1 = xs-offsets, 
		y0 = use.wtreat, 	y1 =	use.wupper)

  
# Points and N descriptions
	points(xs-offsets, use.wtreat,
	       cex = point.size,
	       pch = 21, 
	       bg = 'white',
	       col = 'black')
	text(xs-offsets,use.wtreat,
	     paste('(',use.Nwtreat,')',sep = ''),
	     cex = cex.N,
	     #adj = top.text.adj
	     pos = 1)
	
	points(xs+offsets, use.btreat,
	       pch = 16,
	       cex = point.size)
	text(xs+offsets,use.btreat,
	     paste('(',use.Nbtreat,')',sep = ''),
	     cex = cex.N,
	     #adj = bottom.text.adj
	     pos = 3)
# Formatting
	axis(side = 1,
		at = xs,
		label = seq(100,1000,100),
		cex.axis = cex.axis)
	axis(side = 2,
		at = ys,
		label = ys.lab,
		cex.axis = cex.axis)	
	
# Editing the loop seems to have made the figure less accurate/less similar to the paper especially in regards to the confidence interval. 

```


*Note*: Difference-in-differences results for treatment groups defined by increasing distance from the demolished projects. Differences are for the mean turnout in 2004 minus the mean turnout in 2000 for the treatment group minus the same difference for the control group. White circles represent the mean effect on white voters; black circles represent the mean effect on black voters. The N in each treatment group is in parentheses next to the mean effect. Vertical lines represent the 95% confidence intervals generated by bootstrapped standard errors of the difference between treatment and control.

# Figure 2 Treatment Effects Using Matched White Voters Near Nondemolished Projects for Control Group

```{r fig 2 and 3, echo=FALSE, message=FALSE, warning=FALSE}
# Figure 2 

# Removed parts of this code by trial and error because I originally got several different 
# graphs in addition to the ones created in the paper.
# Not really sure how to separate the figures into different code chunks.
# EDIT: getting rid of for loop makes plots separable
# NOTE: for the figures below, I created dataframes, but they are filled with NA values. I know the 
# various forloops save the values in the data, but my computer was taking extremely long to run them,
# so the data I created is primarily for figure 1, and various csvs are loaded throughout.
# Had the loops worked on my computer, I would have followed the same process as I did for Figure 1.
# The empty matrices created with res.mat would have been filled with values from the forloop.
# Then, instead of reading in the data as csvs, I would have turned the matrices into dataframes
# using as.data.frame with their same names necessary for plotting.
treat <- read_csv('dataverse_files/white.match.nondemolished.csv')
diffs <- read_csv('dataverse_files/white.match.nondemolished.diffs.csv')

			use.ylims = ylims
			use.ys.lab = ys.lab
			use.ys = ys
	
			use.treat = treat$coefficient			
			clower = use.treat-(1.96*treat$stdev)
			cupper = use.treat+(1.96*treat$stdev)
			use.N.treat = treat$N.treatment + treat$N.control
						
			par(las = 1)
			par(mar = c(5.1, 4.1, .5, .5))
			plot(xs, use.treat,
				ylim = use.ylims,
				xlim = xlims,
				type = 'n',
				ylab = 'Treatment Effect',
				xlab = 'Treated Group Distance from Projects',
				xaxt = 'n',
				yaxt = 'n')
			abline(h = 0, lty = 2)
				
			segments(x0=xs,x1=xs,
						y0= use.treat+line.offset,y1=cupper)
			segments(x0=xs,x1=xs,
						y0= use.treat,y1=clower)
	
# Treatment Effects.
# Not totally sure what all of this does. 
			
			points(xs, use.treat, 
				pch = 17, 
				cex = point.size,
					bg = 'white',
       			col = 'black')
			text(xs,use.treat,
			     paste('(',use.N.treat,')',sep = ''),
			     cex = cex.N,
			     pos = 3)
			axis(side = 1,
					at = xs,
					label = seq(100,1000,100),
					cex.axis = cex.axis)
			axis(side = 2,
					at = use.ys,
					label = use.ys.lab,
					cex.axis = cex.axis)
	
```


*Note*: Coefficients on treatment as defined by increasing distance from the demolished projects from OLS regressions on change in turnout from 2000 to 2004 (triangles). N for the regression using matched groups is next to the point representing the coefficient. The treatment group is matched to a control group of white voters living near projects that were not demolished, using nearest neighbor matching. Regressions include variables used in matching as controls. Vertical lines represent the 95% confidence intervals generated by bootstrapped standard errors on the treatment coefficient.


# Figure 3 Treatment Effects Using Matched Black Control Groupand Controlling for Homeownership

```{r fig3, echo=FALSE, message=FALSE, warning=FALSE}
# The same data creation scenario from figure 2 applies here.

treat3 <- read_csv('dataverse_files/white.match.black.property.csv')
diffs3 <- read_csv('dataverse_files/white.match.black.diffs.property.csv')

use.ylims = ylims
			use.ys.lab = ys.lab
			use.ys = ys
	
			use.treat = treat3$coefficient			
			clower = use.treat-(1.96*treat3$stdev)
			cupper = use.treat+(1.96*treat3$stdev)
			use.N.treat = treat3$N.treatment + treat3$N.control
						
			par(las = 1)
			par(mar = c(5.1, 4.1, .5, .5))
			plot(xs, use.treat,
				ylim = use.ylims,
				xlim = xlims,
				type = 'n',
				ylab = 'Treatment Effect',
				xlab = 'Treated Group Distance from Projects',
				xaxt = 'n',
				yaxt = 'n')
			abline(h = 0, lty = 2)
				
			segments(x0=xs,x1=xs,
						y0= use.treat+line.offset,y1=cupper)
			segments(x0=xs,x1=xs,
						y0= use.treat,y1=clower)
	
# Treatment Effects.
# Not totally sure what all of this does. 
			
			points(xs, use.treat, 
				pch = 17, 
				cex = point.size,
					bg = 'white',
       			col = 'black')
			text(xs,use.treat,
			     paste('(',use.N.treat,')',sep = ''),
			     cex = cex.N,
			     pos = 3)
			axis(side = 1,
					at = xs,
					label = seq(100,1000,100),
					cex.axis = cex.axis)
			axis(side = 2,
					at = use.ys,
					label = use.ys.lab,
					cex.axis = cex.axis)

```


*Note*: Coefficients on treatment as defined by increasing distance from the demolished projects from OLS regressions on change in turnout from 2004 to 2000 (triangles). N for the regression using matched groups is next to the point representing the coefficient. The white treatment group is matched to a black control group of the same N using nearest neighbor matching and including variables on homeownership and home value. Regressions include variables used in matching as controls. Vertical lines represent the 95% confidence intervals generated by bootstrapped standard errors on the treatment coefficient.

# Figure 4 Effects of Distance and Size of Projects

```{r fig4a, echo=FALSE, message=FALSE, warning=FALSE}
# Figure 4a. Same data creation scenario.

distdat = read.csv('dataverse_files/predicted.results.distance.vary.context.csv')
colnames(distdat) <- c("mean","sd","50%","2.5%","97.5%")


# New ylims for these graphs
ylims.predict = c(.6,.75)

# Parameters to be used in graphs.
xsa = seq(from = 10, to = 2000, by = 10)


		par(las = 1)
		par(mar = c(5.1, 4.1, .5, .5), mai = c(1.22,0.82,0.82,0.1))
		plot(xsa, distdat[,'mean'],
			type = 'l',
			xlab = 'Distance from Project',
			ylab = expression(Pr(vote[2004])),
			ylim = ylims.predict,
			xaxt = 'n',
			cex.axis = cex.axis,
			lwd = 4)
		
# Put horizontal and vertical lines on plots.
	abline(h = seq(from = min(ylims.predict), to = max(ylims.predict), by = .025),
	       lty = 2,
	       col = 'gray',
	       lwd = 1)
	abline(v = seq(from = 0, to = 2000, by = 200), 
	       lty = 2,
	       col = 'gray',
	       lwd = 1)
	lines(xsa, distdat[,'2.5%'],
			lty = 3,
			lwd = 2.5)
	lines(xsa, distdat[,'97.5%'],
			lty = 3,
			lwd = 2.5)

axis(side = 1, 
		at = seq(from = 0, to = 2000, by = 200),
     labels = as.character(seq(from = 0, to = 2000, by = 200)),
		cex.axis = cex.axis)
```


```{r fig4b, echo=FALSE, message=FALSE, warning=FALSE}
# Figure 4b Same data creation scenario.
areadat = read.csv('dataverse_files/predicted.results.area.vary.context.csv')
colnames(areadat) <- c("mean","sd","50%","2.5%","97.5%")

# Parameters.
xsb = seq(from = 45000, to = 1004000, by = 4800)/1000

	par(las = 1)
		par(mar = c(5.1, 4.1, .5, .5), mai = c(1.22,0.82,0.82,0.1))
		plot(xsb, areadat[,'mean'],
			type = 'l',
			xlab = 'Percent of Local Black Population in Demolished Project',
			ylab = expression(Pr(vote[2004])),
			ylim = ylims.predict,
			xaxt = 'n',
			cex.axis = cex.axis,
			lwd = 4)
		
# Put horizontal and vertical lines on plots
	abline(h = seq(from = min(ylims.predict), to = max(ylims.predict), by = .025),
	       lty = 2,
	       col = 'gray',
	       lwd = 1)
	abline(v = seq(from = 0, to = 2000, by = 200), 
	       lty = 2,
	       col = 'gray',
	       lwd = 1)
	lines(xsb, areadat[,'2.5%'],
			lty = 3,
			lwd = 2.5)
	lines(xsb, areadat[,'97.5%'],
			lty = 3,
			lwd = 2.5)
	

  axis(side = 1, 
		at = seq(from = 0, to = 1000, by = 100),
		# Hard coding axis labels. Help from Enxhis code from class.
     labels = as.character(c('0','10%','20%','30%','40%','50%','60%','70%','80%','90%','100%')),
		cex.axis = cex.axis)

```


*Note*: Predicted effects generated from vote2004 = 􏰀0 + 􏰀1(log(distance)) + 􏰀2(log(localpercent)) + vote2000, with white voters. Figure 4(a) is the predicted probability that a person who voted in 2000 will vote in 2004 with increasing distance, while holding size at its mean. Figure 4(b) is the predicted probability that a person who voted in 2000 will vote in 2004, with increasing outgroup population size, with distance = 100. Dotted lines represent 95% confidence intervals generated by bootstrapped standard errors.


# Figure 5


```{r fig5, echo=FALSE, message=FALSE, warning=FALSE}
# Figure 5
# Again, I couldn't figure out how to break up the figures into different chunks.
# UPDATE: editing the loop allows figures to be separated.

pres.elections = c('dole_pct_ei','bush2000_pct_ei','bush2004_pct_ei','mccain_pct_ei')
obama.elections = c('obama_sen_primary_pct_ei','keyes_pct_ei','obama_pres_primary_pct_ei')

dists = read.csv('dataverse_files/distance.vote.differences.csv')
demos = read.csv('dataverse_files/demolished.vote.differences.csv')


graphs = c('5a','5b')

for(i in graphs){
	if(i == '5a'){dat = dists}
	else{dat = demos}
		
	if(i %in% c('5a','5b')){
		xlims = c(.75, 4.25)
		ylims = c(-.1, .2)	
		}

# Recode Keyes to Obama general for presentation purposes
	dat[dat$election == 'keyes_pct_ei','x.mean'] = 1 - dat[dat$election == 'keyes_pct_ei','x.mean']
	
	dat[dat$election == 'keyes_pct_ei','y.mean'] = 1 - dat[dat$election == 'keyes_pct_ei','y.mean']
	
	dat[dat$election == 'keyes_pct_ei','diff'] =dat[dat$election == 'keyes_pct_ei','y.mean'] - dat[dat$election == 'keyes_pct_ei','x.mean']
	
		par(las = 1)
		par(mar = c(5.1, 4.1, .5, 1.5))
		plot(seq(1:4),
			rep(1,4),
			ylim = ylims,
			xlim = xlims, 
			type = 'n',
			xaxt = 'n',
			yaxt = 'n',
			xlab = 'Election',
			ylab = ifelse(i == '5b','','Treatment Effect')
			)
		abline(h=0, lty = 2)
		
		if(i %in% c('5a','5b')){
			segments(
				x0 = seq(1:4) - offsets, 
				x1 = seq(1:4) - offsets,
				y0 = dat[dat$group == 'white'&dat$election %in% pres.elections,'diff']-(1.96*dat[dat$group == 'white'&dat$election %in% pres.elections,'sd']),
				y1 =	dat[dat$group == 'white'&dat$election %in% pres.elections,'diff']+(1.96*dat[dat$group == 'white'&dat$election %in% pres.elections,'sd'])	
					)
			points(seq(1:4) - offsets,
				dat[dat$group == 'white'&dat$election %in% pres.elections,'diff'],
					pch = 21, 
					bg = 'white',
					col = 'black',
					cex = 2
				)
			segments(
				x0= seq(1:4)+offsets, 
				x1 = seq(1:4)+offsets,
				y0 = dat[dat$group == 'black'&dat$election %in% pres.elections,'diff']-(1.96*dat[dat$group == 'black'&dat$election %in% pres.elections,'sd']),
				y1 =	dat[dat$group == 'black'&dat$election %in% pres.elections,'diff']+(1.96*dat[dat$group == 'black'&dat$election %in% pres.elections,'sd'])	
					)
			points(seq(1:4)+offsets,
				dat[dat$group == 'black'&dat$election %in% pres.elections,'diff'],
					pch = 16,
					cex = 2
				)
			axis(side = 1, at = seq(1:4), 
				c('1996','2000','2004','2008'), 
				tick = F,
				cex.axis = cex.axis)		
		}
		
		else{
			segments(
				x0= seq(1:3)-offsets, 
				x1 = seq(1:3)-offsets,
				y0 = dat[dat$group == 'white'&dat$election %in% obama.elections,'diff']-(1.96*dat[dat$group == 'white'&dat$election %in% obama.elections,'sd']),
				y1 =	dat[dat$group == 'white'&dat$election %in% obama.elections,'diff']+(1.96*dat[dat$group == 'white'&dat$election %in% obama.elections,'sd'])
					)
		  
			points(seq(1:3)-offsets,
				dat[dat$group == 'white'&dat$election %in% obama.elections,'diff'],
					pch = 21, 
					bg = 'white',
					col = 'black',
					cex = 2
				)
			
			segments(
				x0= seq(1:3)+offsets, 
				x1 = seq(1:3)+offsets,
				y0 = dat[dat$group == 'black'&dat$election %in% obama.elections,'diff']-(1.96*dat[dat$group == 'black'&dat$election %in% obama.elections,'sd']),
				y1 =	dat[dat$group == 'black'&dat$election %in% obama.elections,'diff']+(1.96*dat[dat$group == 'black'&dat$election %in% obama.elections,'sd'])	        )
			
  			points(seq(1:3)+offsets,
				dat[dat$group == 'black'&dat$election %in% obama.elections,'diff'],
					pch = 16,
					cex = 2
				)
  			
		axis(side = 1, at = seq(1:3), 
					c('2004 \n Senate Primary','2004 \n Senate General','2008 \n President Primary'),
					tick = F,
					cex.axis = cex.axis
					)
			axis(side = 2,
			at = seq(from = -.1, to = .3, by = .05),
			label = c('-0.10','-0.05','0.00','0.05','0.10','0.15','0.20','0.25','0.30'),
			cex.axis = cex.axis)
	}
		}
		
			
				
```


*Note*: Figure 5(a) shows differences in weighted mean Republican vote for precincts with d ≤ 1,000 and matched precincts with d > 1,000 for white voters (white circles) and black voters (black circles). Figure 5(b) shows differences in weighted mean Republican vote for white voters and black voters matched with precincts with d ≤ 1,000 from nondemolished projects.

# Figure 6
```{r fig6, echo=FALSE, message=FALSE, warning=FALSE}
# Figure 6. Same data read in problem.
pres.elections = c('dole_pct_ei','bush2000_pct_ei','bush2004_pct_ei','mccain_pct_ei')
obama.elections = c('obama_sen_primary_pct_ei','keyes_pct_ei','obama_pres_primary_pct_ei')

dists = read.csv('dataverse_files/distance.vote.differences.csv')
demos = read.csv('dataverse_files/demolished.vote.differences.csv')


graphs = c('6')

for(i in graphs){
	if(i == '5a'){dat = dists}
	else{dat = demos}
		
	if(i %in% c('5a','5b')){
		xlims = c(.75, 4.25)
		ylims = c(-.1, .2)	
		}

# Recode Keyes to Obama general for presentation purposes
	dat[dat$election == 'keyes_pct_ei','x.mean'] = 1 - dat[dat$election == 'keyes_pct_ei','x.mean']
	
	dat[dat$election == 'keyes_pct_ei','y.mean'] = 1 - dat[dat$election == 'keyes_pct_ei','y.mean']
	
	dat[dat$election == 'keyes_pct_ei','diff'] =dat[dat$election == 'keyes_pct_ei','y.mean'] - dat[dat$election == 'keyes_pct_ei','x.mean']
	
		par(las = 1)
		par(mar = c(5.1, 4.1, .5, 1.5))
		plot(seq(1:4),
			rep(1,4),
			ylim = ylims,
			xlim = xlims, 
			type = 'n',
			xaxt = 'n',
			yaxt = 'n',
			xlab = 'Election',
			ylab = ifelse(i == '5b','','Treatment Effect')
			)
		abline(h=0, lty = 2)
		
		if(i %in% c('5a','5b')){
			segments(
				x0 = seq(1:4) - offsets, 
				x1 = seq(1:4) - offsets,
				y0 = dat[dat$group == 'white'&dat$election %in% pres.elections,'diff']-(1.96*dat[dat$group == 'white'&dat$election %in% pres.elections,'sd']),
				y1 =	dat[dat$group == 'white'&dat$election %in% pres.elections,'diff']+(1.96*dat[dat$group == 'white'&dat$election %in% pres.elections,'sd'])	
					)
			points(seq(1:4) - offsets,
				dat[dat$group == 'white'&dat$election %in% pres.elections,'diff'],
					pch = 21, 
					bg = 'white',
					col = 'black',
					cex = 2
				)
			segments(
				x0= seq(1:4)+offsets, 
				x1 = seq(1:4)+offsets,
				y0 = dat[dat$group == 'black'&dat$election %in% pres.elections,'diff']-(1.96*dat[dat$group == 'black'&dat$election %in% pres.elections,'sd']),
				y1 =	dat[dat$group == 'black'&dat$election %in% pres.elections,'diff']+(1.96*dat[dat$group == 'black'&dat$election %in% pres.elections,'sd'])	
					)
			points(seq(1:4)+offsets,
				dat[dat$group == 'black'&dat$election %in% pres.elections,'diff'],
					pch = 16,
					cex = 2
				)
			axis(side = 1, at = seq(1:4), 
				c('1996','2000','2004','2008'), 
				tick = F,
				cex.axis = cex.axis)		
		}
		
		else{
			segments(
				x0= seq(1:3)-offsets, 
				x1 = seq(1:3)-offsets,
				y0 = dat[dat$group == 'white'&dat$election %in% obama.elections,'diff']-(1.96*dat[dat$group == 'white'&dat$election %in% obama.elections,'sd']),
				y1 =	dat[dat$group == 'white'&dat$election %in% obama.elections,'diff']+(1.96*dat[dat$group == 'white'&dat$election %in% obama.elections,'sd'])
					)
		  
			points(seq(1:3)-offsets,
				dat[dat$group == 'white'&dat$election %in% obama.elections,'diff'],
					pch = 21, 
					bg = 'white',
					col = 'black',
					cex = 2
				)
			
			segments(
				x0= seq(1:3)+offsets, 
				x1 = seq(1:3)+offsets,
				y0 = dat[dat$group == 'black'&dat$election %in% obama.elections,'diff']-(1.96*dat[dat$group == 'black'&dat$election %in% obama.elections,'sd']),
				y1 =	dat[dat$group == 'black'&dat$election %in% obama.elections,'diff']+(1.96*dat[dat$group == 'black'&dat$election %in% obama.elections,'sd'])	        )
			
  			points(seq(1:3)+offsets,
				dat[dat$group == 'black'&dat$election %in% obama.elections,'diff'],
					pch = 16,
					cex = 2
				)
  			
		axis(side = 1, at = seq(1:3), 
					c('2004 \n Senate Primary','2004 \n Senate General','2008 \n President Primary'),
					tick = F,
					cex.axis = cex.axis
					)
			axis(side = 2,
			at = seq(from = -.1, to = .3, by = .05),
			label = c('-0.10','-0.05','0.00','0.05','0.10','0.15','0.20','0.25','0.30'),
			cex.axis = cex.axis)
	}
		}


```


*Note*: Differences in weighted mean Obama vote for precincts with d ≤ 1,000 for de- molished projects and matched precincts with d ≤ 1,000 for nondemolished projects for white voters (white circles) and black voters (black circles).


# References

Enos, Ryan D. 2016. “What the Demolition of Public Housing Teaches Us about the Impact of Racial Threat on Political Behavior.” American Journal of Political Science 60 (1): 123-142

